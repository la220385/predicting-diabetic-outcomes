# Model Selection and Evaluation in Predicting Diabetic Outcomes

## Project Overview
This README details my (Latifah J.'s) contributions to the "Predicting Diabetic Outcomes" project. My role was centered around the selection and evaluation of various supervised learning models to better predict diabetes outcomes using key features like BMI, Weight in Kilograms, and previous health conditions.

## Objectives
- Compare and evaluate the performance of different supervised learning models.
- Provide insights into model performance based on advanced visual analytics.

## Files
- `Diabetes_Outcomes_Modeling.ipynb`: Jupyter notebook containing all the model training, comparison, and evaluation code.
- `Correlation Heatmap.png`: Visualization of feature correlations.
- `ROC Curve Comparison.png`: ROC curve analysis of model performance.

## Installation and Setup
```bash
# Clone the repository
git clone https://github.com/HanaDoubleU/predicting-diabetic-outcomes

# Navigate into the project directory
cd project4-group9

# Install required Python libraries
pip install pandas seaborn matplotlib scikit-learn

## Model Selection and Insights

### Models Evaluated
- **Random Forest Classifier**
- **Logistic Regression**

### Approach
- **Model Evaluation**: Employed metrics like AUC, accuracy, precision, recall, and F1 score for thorough comparison.
- **Visual Analysis**: Analyzed underlying data patterns and correlations through extensive visualizations, such as the correlation heatmap and ROC curves, to understand feature impacts and model efficacy.

## Key Visualizations and Their Insights

### Correlation Heatmap
- **Purpose**: To identify multicollinearity and the strength of the relationships between features like BMI, Weight, and their correlation with diabetic outcomes.
- **Insight**: Noted high correlation between BMI and Weight in Kilograms, suggesting potential issues with multicollinearity that could influence model predictions.

### ROC Curve Comparison
- **Purpose**: To compare the true positive rate and false positive rate of Logistic Regression and Random Forest Classifier.
- **Insight**: Both models performed comparably, with Logistic Regression slightly edging out due to better interpretability and simplicity, which is crucial for clinical settings.

## Conclusion
My contributions to this project have provided a deeper understanding of how different models perform in predicting diabetic outcomes and the importance of feature selection and model interpretability in healthcare applications. This experience has enhanced my skills in model evaluation and data visualization, critical for data-driven decision-making in medical fields.

## Tools and Resources Used
- **Python Libraries**: Pandas, Seaborn, Matplotlib, Scikit-Learn
- **Jupyter Notebook**: For interactive development and testing
- **Git**: For version control


# Clone the repository
git clone https://github.com/HanaDoubleU/predicting-diabetic-outcomes

# Navigate into the project directory
cd project4-group9

# Install required Python libraries
pip install pandas seaborn matplotlib scikit-learn

## Model Selection and Insights

### Models Evaluated
- **Random Forest Classifier**
- **Logistic Regression**

### Approach
- **Model Evaluation**: Employed metrics like AUC, accuracy, precision, recall, and F1 score for thorough comparison.
- **Visual Analysis**: Analyzed underlying data patterns and correlations through extensive visualizations, such as the correlation heatmap and ROC curves, to understand feature impacts and model efficacy.

## Key Visualizations and Their Insights

### Correlation Heatmap
- **Purpose**: To identify multicollinearity and the strength of the relationships between features like BMI, Weight, and their correlation with diabetic outcomes.
- **Insight**: Noted high correlation between BMI and Weight in Kilograms, suggesting potential issues with multicollinearity that could influence model predictions.

### ROC Curve Comparison
- **Purpose**: To compare the true positive rate and false positive rate of Logistic Regression and Random Forest Classifier.
- **Insight**: Both models performed comparably, with Logistic Regression slightly edging out due to better interpretability and simplicity, which is crucial for clinical settings.

## Conclusion
My contributions to this project have provided a deeper understanding of how different models perform in predicting diabetic outcomes and the importance of feature selection and model interpretability in healthcare applications. This experience has enhanced my skills in model evaluation and data visualization, critical for data-driven decision-making in medical fields.

## Tools and Resources Used
- **Python Libraries**: Pandas, Seaborn, Matplotlib, Scikit-Learn
- **Jupyter Notebook**: For interactive development and testing
- **Git**: For version control
